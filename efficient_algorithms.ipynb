{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column names\n",
    "column_names = [\n",
    "    'age','workclass','fnlwgt','education','education-num',\n",
    "    'marital-status','occupation','relationship','race','sex',\n",
    "    'capital-gain','capital-loss','hours-per-week','native-country','salary'\n",
    "]\n",
    "# read in the training data\n",
    "df = pd.read_csv(\n",
    "    'adult.data',\n",
    "    names=column_names,\n",
    "    na_values='?',\n",
    "    skipinitialspace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missingness (%):\n",
      " occupation        5.660146\n",
      "workclass         5.638647\n",
      "native-country    1.790486\n",
      "age               0.000000\n",
      "fnlwgt            0.000000\n",
      "education         0.000000\n",
      "education-num     0.000000\n",
      "marital-status    0.000000\n",
      "relationship      0.000000\n",
      "race              0.000000\n",
      "sex               0.000000\n",
      "capital-gain      0.000000\n",
      "capital-loss      0.000000\n",
      "hours-per-week    0.000000\n",
      "salary            0.000000\n",
      "dtype: float64 \n",
      "\n",
      "              age                          fnlwgt                        \\\n",
      "             mean        std  count          mean            std  count   \n",
      "salary                                                                    \n",
      "<=50K   36.783738  14.020088  24720  190340.86517  106482.271195  24720   \n",
      ">50K    44.249841  10.519028   7841  188005.00000  102541.775472   7841   \n",
      "\n",
      "       education-num                  capital-gain                       \\\n",
      "                mean       std  count         mean           std  count   \n",
      "salary                                                                    \n",
      "<=50K       9.595065  2.436147  24720   148.752468    963.139307  24720   \n",
      ">50K       11.611657  2.385129   7841  4006.142456  14570.378951   7841   \n",
      "\n",
      "       capital-loss                    hours-per-week                    \n",
      "               mean         std  count           mean        std  count  \n",
      "salary                                                                   \n",
      "<=50K     53.142921  310.755769  24720      38.840210  12.318995  24720  \n",
      ">50K     195.001530  595.487574   7841      45.473026  11.012971   7841   \n",
      "\n",
      "Numeric → salary correlation:\n",
      " education-num     0.335154\n",
      "age               0.234037\n",
      "hours-per-week    0.229689\n",
      "capital-gain      0.223329\n",
      "capital-loss      0.150526\n",
      "fnlwgt            0.009463\n",
      "Name: salary_bin, dtype: float64 \n",
      "\n",
      "Categorical → salary (Chi2 p-values):\n",
      "               var         chi2              p\n",
      "1       education  4429.653302   0.000000e+00\n",
      "2  marital-status  6517.741654   0.000000e+00\n",
      "3      occupation  3744.898758   0.000000e+00\n",
      "4    relationship  6699.076897   0.000000e+00\n",
      "6             sex  1517.813409   0.000000e+00\n",
      "0       workclass   827.718359  1.933848e-174\n",
      "5            race   330.920431   2.305961e-70\n",
      "7  native-country   317.087663   8.280446e-45 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Missingness (%):\\n\", (df.isna().mean()*100).sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "numeric_cols = ['age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']\n",
    "print(df.groupby('salary')[numeric_cols].agg(['mean','std','count']), \"\\n\")\n",
    "\n",
    "# Correlation of numeric variables vs salary\n",
    "df['salary_bin'] = df['salary'].map({'<=50K':0,'>50K':1})\n",
    "corrs = df[numeric_cols + ['salary_bin']].corr()['salary_bin'].drop('salary_bin').abs().sort_values(ascending=False)\n",
    "print(\"Numeric → salary correlation:\\n\", corrs, \"\\n\")\n",
    "\n",
    "# Chi-squared for categorical variables vs salary\n",
    "cat_cols = [\n",
    "    'workclass','education','marital-status','occupation',\n",
    "    'relationship','race','sex','native-country'\n",
    "]\n",
    "chi2 = []\n",
    "for c in cat_cols:\n",
    "    tbl = pd.crosstab(df[c], df['salary'])\n",
    "    stat,p,_,_ = chi2_contingency(tbl)\n",
    "    chi2.append((c, stat, p))\n",
    "chi2_df = pd.DataFrame(chi2, columns=['var','chi2','p']).sort_values('p')\n",
    "print(\"Categorical → salary (Chi2 p-values):\\n\", chi2_df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/bvddlspn5_x9srcfwd_gh3lh0000gn/T/ipykernel_1693/1010889129.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].fillna(fill, inplace=True)\n",
      "/var/folders/8x/bvddlspn5_x9srcfwd_gh3lh0000gn/T/ipykernel_1693/1010889129.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].fillna(fill, inplace=True)\n",
      "/var/folders/8x/bvddlspn5_x9srcfwd_gh3lh0000gn/T/ipykernel_1693/1010889129.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].fillna(fill, inplace=True)\n",
      "/var/folders/8x/bvddlspn5_x9srcfwd_gh3lh0000gn/T/ipykernel_1693/1010889129.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].fillna(fill, inplace=True)\n",
      "/var/folders/8x/bvddlspn5_x9srcfwd_gh3lh0000gn/T/ipykernel_1693/1010889129.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].fillna(fill, inplace=True)\n",
      "/var/folders/8x/bvddlspn5_x9srcfwd_gh3lh0000gn/T/ipykernel_1693/1010889129.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].fillna(fill, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# drop columns that we classify as noise\n",
    "df.drop(columns=['fnlwgt','native-country'], inplace=True)\n",
    "\n",
    "# generate net-capital columns\n",
    "df['net-capital'] = df['capital-gain'] - df['capital-loss']\n",
    "df.drop(columns=['capital-loss'], inplace=True)\n",
    "\n",
    "# generate age bins\n",
    "df['age_bin'] = pd.cut(\n",
    "    df['age'],\n",
    "    bins=[16,25,35,45,55,65,100],\n",
    "    labels=['17–25','26–35','36–45','46–55','56–65','65+']\n",
    ")\n",
    "\n",
    "# generate married flag\n",
    "df['married'] = (\n",
    "    df['marital-status'].str.startswith('Married') |\n",
    "    df['relationship'].isin(['Husband','Wife'])\n",
    ").astype(int)\n",
    "\n",
    "# generate education groupings\n",
    "def map_edu(x):\n",
    "    if x=='Bachelors': return 'Bachelors'\n",
    "    if x in ['Masters','Prof-school','Doctorate']: return 'Advanced'\n",
    "    if x in ['HS-grad','Some-college','Assoc-acdm','Assoc-voc']: return 'High-school'\n",
    "    return 'Less-than-HS'\n",
    "df['education_group'] = df['education'].map(map_edu)\n",
    "\n",
    "# drop original variables\n",
    "df.drop(columns=['education','marital-status','relationship'], inplace=True)\n",
    "\n",
    "# impute numeric variables\n",
    "numeric_cols = ['age','education-num','hours-per-week','net-capital','married']\n",
    "num_imp = SimpleImputer(strategy='median')\n",
    "df[numeric_cols] = num_imp.fit_transform(df[numeric_cols])\n",
    "\n",
    "# impute categorical variables with other\n",
    "cat_cols = ['workclass','occupation','race','sex','age_bin','education_group']\n",
    "for c in cat_cols:\n",
    "    vals = df[c].dropna().unique()\n",
    "    fill = 'Other' if 'Other' in vals else df[c].mode()[0]\n",
    "    df[c].fillna(fill, inplace=True)\n",
    "    freqs = df[c].value_counts(normalize=True)\n",
    "    rare = freqs[freqs<0.01].index\n",
    "    df[c] = df[c].replace(rare, 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target variable for classification\n",
    "df['salary_bin'] = df['salary'].str.rstrip('.').map({'<=50K':0,'>50K':1})\n",
    "y = df['salary_bin'].values\n",
    "\n",
    "# encode cats\n",
    "encoders = {}\n",
    "X_cat = {}\n",
    "cardinalities = {}\n",
    "for c in cat_cols:\n",
    "    le = LabelEncoder().fit(df[c])\n",
    "    encoders[c] = le\n",
    "    X_cat[c] = le.transform(df[c])\n",
    "    cardinalities[c] = len(le.classes_) + 1\n",
    "\n",
    "# numeric matrix\n",
    "X_num = df[numeric_cols].values\n",
    "\n",
    "# train/val split\n",
    "idx = np.arange(len(y))\n",
    "train_idx, val_idx = train_test_split(idx, test_size=0.2,\n",
    "                                       random_state=42, stratify=y)\n",
    "X_train_num = X_num[train_idx]; X_val_num = X_num[val_idx]\n",
    "y_train     = y[train_idx];     y_val     = y[val_idx]\n",
    "X_train_cat = {c: X_cat[c][train_idx] for c in cat_cols}\n",
    "X_val_cat   = {c: X_cat[c][val_idx]   for c in cat_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Library/Python/3.9/lib/python/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# stack cats into matrix\n",
    "X_train_cat_arr = np.stack([X_train_cat[c] for c in cat_cols], axis=1)\n",
    "X_train_combined = np.hstack([X_train_num, X_train_cat_arr])\n",
    "\n",
    "# use smote to increase the cases of the minority class in a balanced way\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train_combined, y_train)\n",
    "\n",
    "# split back into numeric & categorical variables\n",
    "n_num = X_train_num.shape[1]\n",
    "X_train_num = X_res[:, :n_num]\n",
    "cat_res = X_res[:, n_num:].astype(int)\n",
    "X_train_cat = {c: cat_res[:, i] for i, c in enumerate(cat_cols)}\n",
    "y_train = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights on the resampled data\n",
    "weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "cw = dict(enumerate(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model using hyperband optimisation\n",
    "def build_model(hp):\n",
    "    inputs, embeds = [], []\n",
    "    # categorical embeddings\n",
    "    for c in cat_cols:\n",
    "        inp   = keras.Input(shape=(1,), name=c)\n",
    "        vocab = cardinalities[c]\n",
    "        emb_dim = hp.Int(f\"{c}_emb\", min_value=5, max_value=100, step=5)\n",
    "        emb   = keras.layers.Embedding(input_dim=vocab, output_dim=emb_dim)(inp)\n",
    "        flat  = keras.layers.Flatten()(emb)\n",
    "        inputs.append(inp); embeds.append(flat)\n",
    "    # numeric input\n",
    "    num_inp = keras.Input(shape=(len(numeric_cols),), name='numeric')\n",
    "    bn      = keras.layers.BatchNormalization()(num_inp)\n",
    "    inputs.append(num_inp); embeds.append(bn)\n",
    "    # concatenate\n",
    "    x = keras.layers.Concatenate()(embeds)\n",
    "    # tunable dense stack\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 5)):\n",
    "        units = hp.Int(f\"units_{i}\", min_value=32, max_value=1024, step=32)\n",
    "        x = keras.layers.Dense(units, activation='relu')(x)\n",
    "        x = keras.layers.Dropout(hp.Float(f\"dropout_{i}\", 0.0, 0.5, step=0.1))(x)\n",
    "    out = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    lr = hp.Float(\"lr\", 1e-5, 1e-2, sampling=\"log\")\n",
    "    model = keras.Model(inputs, out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 01m 19s]\n",
      "val_accuracy: 0.8294180631637573\n",
      "\n",
      "Best val_accuracy So Far: 0.8415476679801941\n",
      "Total elapsed time: 00h 39m 08s\n",
      "Best hyperparameters: {'workclass_emb': 90, 'occupation_emb': 85, 'race_emb': 65, 'sex_emb': 60, 'age_bin_emb': 15, 'education_group_emb': 95, 'num_layers': 4, 'units_0': 320, 'dropout_0': 0.4, 'lr': 0.0005941838658383296, 'units_1': 704, 'dropout_1': 0.0, 'units_2': 288, 'dropout_2': 0.1, 'units_3': 416, 'dropout_3': 0.0, 'units_4': 128, 'dropout_4': 0.1, 'tuner/epochs': 4, 'tuner/initial_epoch': 0, 'tuner/bracket': 2, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "# tune the hyperband optimiser to find the best hyperparameters\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=30,\n",
    "    factor=3,\n",
    "    directory='hyperband_dir',\n",
    "    project_name='adult_income_no_focal'\n",
    ")\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(\n",
    "    {**X_train_cat, 'numeric': X_train_num}, y_train,\n",
    "    epochs=30,\n",
    "    validation_data=({**X_val_cat, 'numeric': X_val_num}, y_val),\n",
    "    callbacks=[early],\n",
    "    class_weight=cw\n",
    ")\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "print(\"Best hyperparameters:\", best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.4104 - val_accuracy: 0.8116 - val_loss: 0.3773\n",
      "Epoch 2/30\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8414 - loss: 0.3554 - val_accuracy: 0.8187 - val_loss: 0.3692\n",
      "Epoch 3/30\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8428 - loss: 0.3499 - val_accuracy: 0.8277 - val_loss: 0.3658\n",
      "Epoch 4/30\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8408 - loss: 0.3526 - val_accuracy: 0.8228 - val_loss: 0.3777\n",
      "Epoch 5/30\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8453 - loss: 0.3442 - val_accuracy: 0.8214 - val_loss: 0.3615\n",
      "Epoch 6/30\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8476 - loss: 0.3393 - val_accuracy: 0.8033 - val_loss: 0.3839\n",
      "Epoch 7/30\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8463 - loss: 0.3405 - val_accuracy: 0.8093 - val_loss: 0.3821\n",
      "Epoch 8/30\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8485 - loss: 0.3350 - val_accuracy: 0.8009 - val_loss: 0.3895\n",
      "Epoch 9/30\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8488 - loss: 0.3368 - val_accuracy: 0.8105 - val_loss: 0.3759\n",
      "Epoch 10/30\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8517 - loss: 0.3333 - val_accuracy: 0.8139 - val_loss: 0.3646\n"
     ]
    }
   ],
   "source": [
    "# build the final model\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(\n",
    "    {**X_train_cat, 'numeric': X_train_num}, y_train,\n",
    "    validation_data=({**X_val_cat, 'numeric': X_val_num}, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early],\n",
    "    class_weight=cw\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/bvddlspn5_x9srcfwd_gh3lh0000gn/T/ipykernel_1693/1497553961.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[c].fillna(fill, inplace=True)\n",
      "/var/folders/8x/bvddlspn5_x9srcfwd_gh3lh0000gn/T/ipykernel_1693/1497553961.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[c].fillna(fill, inplace=True)\n",
      "/var/folders/8x/bvddlspn5_x9srcfwd_gh3lh0000gn/T/ipykernel_1693/1497553961.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[c].fillna(fill, inplace=True)\n",
      "/var/folders/8x/bvddlspn5_x9srcfwd_gh3lh0000gn/T/ipykernel_1693/1497553961.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[c].fillna(fill, inplace=True)\n",
      "/var/folders/8x/bvddlspn5_x9srcfwd_gh3lh0000gn/T/ipykernel_1693/1497553961.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[c].fillna(fill, inplace=True)\n",
      "/var/folders/8x/bvddlspn5_x9srcfwd_gh3lh0000gn/T/ipykernel_1693/1497553961.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[c].fillna(fill, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# read in test data\n",
    "test = pd.read_csv(\n",
    "    'adult.test',\n",
    "    names=column_names,\n",
    "    na_values='?',\n",
    "    skipinitialspace=True,\n",
    "    skiprows=1\n",
    ")\n",
    "# same preprocessing on test data as training data\n",
    "test.drop(columns=['fnlwgt','native-country'], inplace=True)\n",
    "test['net-capital'] = test['capital-gain'] - test['capital-loss']\n",
    "test.drop(columns=['capital-loss'], inplace=True)\n",
    "test['age_bin'] = pd.cut(\n",
    "    test['age'], bins=[16,25,35,45,55,65,100],\n",
    "    labels=['17–25','26–35','36–45','46–55','56–65','65+']\n",
    ")\n",
    "test['married'] = (\n",
    "    test['marital-status'].str.startswith('Married') |\n",
    "    test['relationship'].isin(['Husband','Wife'])\n",
    ").astype(int)\n",
    "test['education_group'] = test['education'].map(map_edu)\n",
    "test.drop(columns=['education','marital-status','relationship'], inplace=True)\n",
    "test[numeric_cols] = num_imp.transform(test[numeric_cols])\n",
    "for c in cat_cols:\n",
    "    vals = test[c].dropna().unique()\n",
    "    fill = 'Other' if 'Other' in vals else test[c].mode()[0]\n",
    "    test[c].fillna(fill, inplace=True)\n",
    "    freqs = test[c].value_counts(normalize=True)\n",
    "    rare = freqs[freqs < 0.01].index\n",
    "    test[c] = test[c].replace(rare, 'Other')\n",
    "test['salary_bin'] = test['salary'].str.rstrip('.').map({'<=50K':0,'>50K':1})\n",
    "y_test     = test['salary_bin'].values\n",
    "X_test_num = test[numeric_cols].values\n",
    "X_test_cat = {c: encoders[c].transform(test[c]) for c in cat_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict({**X_test_cat, 'numeric': X_test_num})\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.93      0.82      0.87     12435\n",
      "        >50K       0.58      0.79      0.67      3846\n",
      "\n",
      "    accuracy                           0.82     16281\n",
      "   macro avg       0.75      0.81      0.77     16281\n",
      "weighted avg       0.85      0.82      0.82     16281\n",
      "\n",
      "F1: 0.66996699669967\n",
      "Precision: 0.5806636155606407\n",
      "Recall: 0.7917316692667706\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8135 - loss: 0.3643\n",
      "Accuracy: 0.8157361149787903\n"
     ]
    }
   ],
   "source": [
    "# print performance metrics of the model\n",
    "print(classification_report(y_test,y_pred,target_names=['<=50K','>50K']))\n",
    "print(\"F1:\", f1_score(y_test,y_pred))\n",
    "print(\"Precision:\", precision_score(y_test,y_pred))\n",
    "print(\"Recall:\", recall_score(y_test,y_pred))\n",
    "print(\"Accuracy:\", model.evaluate({**X_test_cat,'numeric':X_test_num}, y_test)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
